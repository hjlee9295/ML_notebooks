{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AML_HW5_Task1.ipynb","provenance":[{"file_id":"1QS7Rq51mEWh-oynrbYahiZnIek-BRiPD","timestamp":1588208668223}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rFMcX_ilQ6zc","colab_type":"text"},"source":["## Task 1. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"0RZaguRTnAy2","colab_type":"text"},"source":["Hojin Lee (hl3328) & Hyuk Joon Kwon (hk3084)"]},{"cell_type":"code","metadata":{"id":"jpVMMuKzekFZ","colab_type":"code","outputId":"bf313347-215a-4d3f-d992-78e29ab92565","executionInfo":{"status":"ok","timestamp":1587851920804,"user_tz":240,"elapsed":2776,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from keras import regularizers\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from keras.datasets import mnist\n","from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.datasets import load_digits\n","from keras.layers import Dense, Activation, BatchNormalization, Dropout"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wEVsiOfMRlqP","colab_type":"text"},"source":["## Import Data from sklearn.datasets load_digits"]},{"cell_type":"code","metadata":{"id":"evLu7DzpRXMC","colab_type":"code","outputId":"6e477223-806b-4bce-c075-5e4343d76cc9","executionInfo":{"status":"ok","timestamp":1587851924593,"user_tz":240,"elapsed":640,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["digits = load_digits()\n","X = digits.data\n","y = digits.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","# X_train /= 255\n","# X_test /= 255\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')\n","num_classes = 10\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1437 train samples\n","360 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ula-r-ymSC2e","colab_type":"text"},"source":["## The shape of the Data"]},{"cell_type":"code","metadata":{"id":"0ReS7bP8SBg5","colab_type":"code","outputId":"7707b909-a3e3-460a-de89-602bde5851d2","executionInfo":{"status":"ok","timestamp":1587851927567,"user_tz":240,"elapsed":725,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1797, 64)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"kRwx_yvyVxq3","colab_type":"text"},"source":["## This is what a single image looks like (Image representation of the integer 0)"]},{"cell_type":"code","metadata":{"id":"WJnqYvoPVxYg","colab_type":"code","outputId":"9bf293cd-6bc9-4115-de5e-3a9ab4e4d847","executionInfo":{"status":"ok","timestamp":1587851928191,"user_tz":240,"elapsed":669,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["plt.matshow(digits.images[0])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7ff50d45f828>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PKhpO4fLRuDH","colab_type":"code","colab":{}},"source":["def make_model(optimizer=\"adam\",hidden_size=32,reg = 0.01):\n","  model = Sequential([Dense(hidden_size, input_shape=(64,),kernel_regularizer=regularizers.l2(reg), bias_regularizer=regularizers.l2(reg)), \n","                      Activation('relu'), \n","                      BatchNormalization(),\n","                      Dense(hidden_size, kernel_regularizer=regularizers.l2(reg), bias_regularizer=regularizers.l2(reg)), \n","                      Dense(10), \n","                      Activation('softmax')])\n","  model.compile(optimizer = optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy']) \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8EDtOwdtSB9_","colab_type":"code","outputId":"acc5255e-9223-45d6-93c1-95164fe4f3b0","executionInfo":{"status":"error","timestamp":1587852065626,"user_tz":240,"elapsed":105859,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["clf = KerasClassifier(make_model)\n","param_grid = {'epochs': [5,10], 'hidden_size':[32,48,64,128],'reg': [0.1,0.01,0.001]}\n","grid = GridSearchCV(clf,param_grid=param_grid)\n","grid.fit(X_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1149/1149 [==============================] - 0s 405us/step - loss: 8.7801 - accuracy: 0.2550\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 50us/step - loss: 6.4387 - accuracy: 0.6005\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 4.8570 - accuracy: 0.7963\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 46us/step - loss: 3.7589 - accuracy: 0.8660\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 2.9289 - accuracy: 0.9086\n","288/288 [==============================] - 0s 174us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 191us/step - loss: 8.7534 - accuracy: 0.3011\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 6.4115 - accuracy: 0.6823\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 4.8753 - accuracy: 0.8077\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 3.7486 - accuracy: 0.8816\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 53us/step - loss: 2.9184 - accuracy: 0.9104\n","288/288 [==============================] - 0s 162us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 203us/step - loss: 8.7642 - accuracy: 0.2861\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 6.3569 - accuracy: 0.6983\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 4.7693 - accuracy: 0.8296\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 3.6195 - accuracy: 0.8870\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 2.7756 - accuracy: 0.9191\n","287/287 [==============================] - 0s 179us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 208us/step - loss: 8.7339 - accuracy: 0.3339\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 6.3657 - accuracy: 0.6496\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 4.8172 - accuracy: 0.7757\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 3.6850 - accuracy: 0.8522\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 48us/step - loss: 2.8599 - accuracy: 0.8965\n","287/287 [==============================] - 0s 158us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 190us/step - loss: 8.4392 - accuracy: 0.3696\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 6.1331 - accuracy: 0.7330\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 4.5920 - accuracy: 0.8417\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 3.5008 - accuracy: 0.8887\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 2.6813 - accuracy: 0.9252\n","287/287 [==============================] - 0s 157us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 192us/step - loss: 2.3432 - accuracy: 0.4613\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.5379 - accuracy: 0.7563\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.2265 - accuracy: 0.8364\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.0419 - accuracy: 0.8947\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.9215 - accuracy: 0.9104\n","288/288 [==============================] - 0s 180us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 191us/step - loss: 2.7391 - accuracy: 0.3281\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 1.7038 - accuracy: 0.7354\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 1.2767 - accuracy: 0.8468\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.0488 - accuracy: 0.8938\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.9198 - accuracy: 0.9191\n","288/288 [==============================] - 0s 155us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 215us/step - loss: 2.8638 - accuracy: 0.2922\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.8460 - accuracy: 0.6800\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.4024 - accuracy: 0.8165\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.1446 - accuracy: 0.8809\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.9670 - accuracy: 0.9096\n","287/287 [==============================] - 0s 173us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 194us/step - loss: 2.7434 - accuracy: 0.3261\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.8128 - accuracy: 0.7009\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.3681 - accuracy: 0.8165\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 47us/step - loss: 1.1216 - accuracy: 0.8609\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.9640 - accuracy: 0.9052\n","287/287 [==============================] - 0s 162us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 198us/step - loss: 2.7171 - accuracy: 0.3374\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.6945 - accuracy: 0.7191\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.3000 - accuracy: 0.8217\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 40us/step - loss: 1.0751 - accuracy: 0.9035\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.9264 - accuracy: 0.9296\n","287/287 [==============================] - 0s 167us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 197us/step - loss: 2.1353 - accuracy: 0.3011\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 1.1532 - accuracy: 0.7154\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.7380 - accuracy: 0.8364\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.5298 - accuracy: 0.9017\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.4143 - accuracy: 0.9234\n","288/288 [==============================] - 0s 160us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 189us/step - loss: 1.9981 - accuracy: 0.3368\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.1182 - accuracy: 0.7189\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.7704 - accuracy: 0.8320\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.5736 - accuracy: 0.8842\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.4734 - accuracy: 0.9069\n","288/288 [==============================] - 0s 161us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 190us/step - loss: 1.9028 - accuracy: 0.3965\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.0013 - accuracy: 0.7261\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 48us/step - loss: 0.6778 - accuracy: 0.8313\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.5270 - accuracy: 0.8843\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.4133 - accuracy: 0.9165\n","287/287 [==============================] - 0s 177us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 206us/step - loss: 1.9140 - accuracy: 0.3652\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.0257 - accuracy: 0.7678\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.6786 - accuracy: 0.8591\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5086 - accuracy: 0.9061\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.4152 - accuracy: 0.9165\n","287/287 [==============================] - 0s 175us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 202us/step - loss: 1.9972 - accuracy: 0.3539\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.0030 - accuracy: 0.7696\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.6583 - accuracy: 0.8600\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.4854 - accuracy: 0.9165\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.3916 - accuracy: 0.9287\n","287/287 [==============================] - 0s 171us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 210us/step - loss: 10.6435 - accuracy: 0.4500\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 7.3056 - accuracy: 0.8390\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 5.1752 - accuracy: 0.9147\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 3.6745 - accuracy: 0.9347\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 2.6272 - accuracy: 0.9547\n","288/288 [==============================] - 0s 169us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 202us/step - loss: 11.1415 - accuracy: 0.4047\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 7.7870 - accuracy: 0.7963\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 5.6073 - accuracy: 0.8912\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 4.0657 - accuracy: 0.9147\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 2.9477 - accuracy: 0.9452\n","288/288 [==============================] - 0s 164us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 201us/step - loss: 10.6086 - accuracy: 0.4470\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 7.3289 - accuracy: 0.8174\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 5.2242 - accuracy: 0.8957\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 3.7373 - accuracy: 0.9122\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 2.7020 - accuracy: 0.9304\n","287/287 [==============================] - 0s 163us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 195us/step - loss: 11.0001 - accuracy: 0.4348\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 7.5405 - accuracy: 0.7948\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 48us/step - loss: 5.3151 - accuracy: 0.8913\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 3.7621 - accuracy: 0.9200\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 2.6811 - accuracy: 0.9400\n","287/287 [==============================] - 0s 175us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 215us/step - loss: 10.2745 - accuracy: 0.5017\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 7.1226 - accuracy: 0.8348\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 5.0733 - accuracy: 0.9061\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 3.6301 - accuracy: 0.9357\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 2.6175 - accuracy: 0.9539\n","287/287 [==============================] - 0s 187us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 212us/step - loss: 2.8394 - accuracy: 0.3873\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.6382 - accuracy: 0.8181\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.2712 - accuracy: 0.8964\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.0860 - accuracy: 0.9278\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.9718 - accuracy: 0.9408\n","288/288 [==============================] - 0s 172us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 206us/step - loss: 2.5365 - accuracy: 0.4926\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.5664 - accuracy: 0.8538\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.2601 - accuracy: 0.9017\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.0923 - accuracy: 0.9347\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.9764 - accuracy: 0.9530\n","288/288 [==============================] - 0s 165us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 201us/step - loss: 2.9622 - accuracy: 0.3426\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.7150 - accuracy: 0.7904\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 1.3209 - accuracy: 0.8852\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.1205 - accuracy: 0.9130\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.9971 - accuracy: 0.9287\n","287/287 [==============================] - 0s 162us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 199us/step - loss: 2.9286 - accuracy: 0.3774\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 1.6233 - accuracy: 0.8261\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.2402 - accuracy: 0.9017\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.0617 - accuracy: 0.9243\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.9465 - accuracy: 0.9426\n","287/287 [==============================] - 0s 198us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 192us/step - loss: 2.8338 - accuracy: 0.4183\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.5942 - accuracy: 0.8287\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.2853 - accuracy: 0.8948\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.1029 - accuracy: 0.9313\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.9881 - accuracy: 0.9470\n","287/287 [==============================] - 0s 162us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 223us/step - loss: 1.5589 - accuracy: 0.5535\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.6949 - accuracy: 0.8460\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.4590 - accuracy: 0.9112\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 47us/step - loss: 0.3500 - accuracy: 0.9417\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.2935 - accuracy: 0.9582\n","288/288 [==============================] - 0s 177us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 208us/step - loss: 1.7315 - accuracy: 0.4621\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.7334 - accuracy: 0.8425\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.4659 - accuracy: 0.9156\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.3726 - accuracy: 0.9365\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.3122 - accuracy: 0.9521\n","288/288 [==============================] - 0s 178us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 217us/step - loss: 1.7918 - accuracy: 0.4452\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.7597 - accuracy: 0.8226\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.5200 - accuracy: 0.8904\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.3977 - accuracy: 0.9252\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.3288 - accuracy: 0.9374\n","287/287 [==============================] - 0s 170us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 196us/step - loss: 1.8762 - accuracy: 0.4426\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.7787 - accuracy: 0.8287\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.5222 - accuracy: 0.8878\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 47us/step - loss: 0.4007 - accuracy: 0.9200\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.3309 - accuracy: 0.9383\n","287/287 [==============================] - 0s 160us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 193us/step - loss: 1.9728 - accuracy: 0.4052\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.7595 - accuracy: 0.8383\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.4911 - accuracy: 0.9061\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.3656 - accuracy: 0.9383\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.3138 - accuracy: 0.9513\n","287/287 [==============================] - 0s 172us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 196us/step - loss: 12.3175 - accuracy: 0.5483\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 8.1728 - accuracy: 0.8660\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 5.5168 - accuracy: 0.9164\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 3.7301 - accuracy: 0.9391\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 2.5414 - accuracy: 0.9591\n","288/288 [==============================] - 0s 170us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 195us/step - loss: 12.9181 - accuracy: 0.4935\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 47us/step - loss: 8.6711 - accuracy: 0.8303\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 5.9386 - accuracy: 0.8938\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 48us/step - loss: 4.0627 - accuracy: 0.9339\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 2.8214 - accuracy: 0.9460\n","288/288 [==============================] - 0s 156us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 225us/step - loss: 12.5443 - accuracy: 0.4965\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 8.3660 - accuracy: 0.8609\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 5.7061 - accuracy: 0.9000\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 3.8742 - accuracy: 0.9357\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 2.6576 - accuracy: 0.9565\n","287/287 [==============================] - 0s 179us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 212us/step - loss: 12.5991 - accuracy: 0.5243\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 8.4063 - accuracy: 0.8530\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 5.6990 - accuracy: 0.9217\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 49us/step - loss: 3.8405 - accuracy: 0.9443\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 2.6092 - accuracy: 0.9548\n","287/287 [==============================] - 0s 172us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 212us/step - loss: 12.5664 - accuracy: 0.5000\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 8.2834 - accuracy: 0.8670\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 5.5834 - accuracy: 0.9174\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 3.7649 - accuracy: 0.9452\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 2.5468 - accuracy: 0.9539\n","287/287 [==============================] - 0s 168us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 211us/step - loss: 2.6330 - accuracy: 0.5657\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 1.5707 - accuracy: 0.8938\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.3127 - accuracy: 0.9356\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.1628 - accuracy: 0.9539\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.0502 - accuracy: 0.9617\n","288/288 [==============================] - 0s 194us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 197us/step - loss: 2.8165 - accuracy: 0.5013\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 1.6218 - accuracy: 0.8703\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.3288 - accuracy: 0.9260\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 53us/step - loss: 1.1661 - accuracy: 0.9434\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 1.0376 - accuracy: 0.9582\n","288/288 [==============================] - 0s 167us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 192us/step - loss: 2.6713 - accuracy: 0.5417\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.6325 - accuracy: 0.8513\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.3282 - accuracy: 0.9191\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.1705 - accuracy: 0.9435\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.0445 - accuracy: 0.9591\n","287/287 [==============================] - 0s 158us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 186us/step - loss: 2.6659 - accuracy: 0.5583\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 1.5960 - accuracy: 0.8748\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 1.3128 - accuracy: 0.9330\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.1593 - accuracy: 0.9504\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 1.0314 - accuracy: 0.9609\n","287/287 [==============================] - 0s 153us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 189us/step - loss: 2.7166 - accuracy: 0.5304\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 1.6042 - accuracy: 0.8878\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 1.3195 - accuracy: 0.9409\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 51us/step - loss: 1.1370 - accuracy: 0.9626\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.0192 - accuracy: 0.9661\n","287/287 [==============================] - 0s 170us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 225us/step - loss: 1.7675 - accuracy: 0.4717\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.6777 - accuracy: 0.8668\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.4353 - accuracy: 0.9295\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.3419 - accuracy: 0.9426\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.2653 - accuracy: 0.9721\n","288/288 [==============================] - 0s 176us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 212us/step - loss: 1.5984 - accuracy: 0.5213\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.6079 - accuracy: 0.8764\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 0.4281 - accuracy: 0.9234\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.3394 - accuracy: 0.9521\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.2916 - accuracy: 0.9530\n","288/288 [==============================] - 0s 187us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 220us/step - loss: 1.5936 - accuracy: 0.5365\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5802 - accuracy: 0.8809\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.4106 - accuracy: 0.9252\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.3237 - accuracy: 0.9539\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.2851 - accuracy: 0.9548\n","287/287 [==============================] - 0s 168us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 214us/step - loss: 1.5651 - accuracy: 0.5687\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.6155 - accuracy: 0.8904\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.4191 - accuracy: 0.9278\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.3382 - accuracy: 0.9478\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.2622 - accuracy: 0.9678\n","287/287 [==============================] - 0s 170us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 197us/step - loss: 1.4544 - accuracy: 0.5965\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 0.5469 - accuracy: 0.8983\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.3795 - accuracy: 0.9383\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.3056 - accuracy: 0.9522\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.2573 - accuracy: 0.9713\n","287/287 [==============================] - 0s 170us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 206us/step - loss: 18.5784 - accuracy: 0.6606\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 54us/step - loss: 10.7663 - accuracy: 0.9304\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 53us/step - loss: 6.1326 - accuracy: 0.9487\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 3.4825 - accuracy: 0.9600\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 53us/step - loss: 2.0541 - accuracy: 0.9695\n","288/288 [==============================] - 0s 154us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 195us/step - loss: 18.3929 - accuracy: 0.7171\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 10.4814 - accuracy: 0.9330\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 5.8356 - accuracy: 0.9452\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 3.2650 - accuracy: 0.9626\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 1.8906 - accuracy: 0.9678\n","288/288 [==============================] - 0s 157us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 200us/step - loss: 18.8906 - accuracy: 0.6739\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 10.9378 - accuracy: 0.9130\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 6.2081 - accuracy: 0.9391\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 50us/step - loss: 3.5318 - accuracy: 0.9565\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 56us/step - loss: 2.0619 - accuracy: 0.9722\n","287/287 [==============================] - 0s 158us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 193us/step - loss: 18.3637 - accuracy: 0.7061\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 49us/step - loss: 10.5932 - accuracy: 0.9348\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 50us/step - loss: 5.9741 - accuracy: 0.9522\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 51us/step - loss: 3.3799 - accuracy: 0.9583\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 51us/step - loss: 1.9825 - accuracy: 0.9600\n","287/287 [==============================] - 0s 156us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 233us/step - loss: 18.3470 - accuracy: 0.7061\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 10.5013 - accuracy: 0.9383\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 51us/step - loss: 5.8693 - accuracy: 0.9522\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 3.2701 - accuracy: 0.9643\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 1.8791 - accuracy: 0.9713\n","287/287 [==============================] - 0s 177us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 218us/step - loss: 2.8943 - accuracy: 0.7337\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 1.9673 - accuracy: 0.9574\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 1.6760 - accuracy: 0.9695\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 1.4339 - accuracy: 0.9835\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 53us/step - loss: 1.2293 - accuracy: 0.9887\n","288/288 [==============================] - 0s 173us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 220us/step - loss: 2.9808 - accuracy: 0.7119\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 58us/step - loss: 1.9718 - accuracy: 0.9452\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 1.6713 - accuracy: 0.9678\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 1.4396 - accuracy: 0.9835\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 1.2473 - accuracy: 0.9861\n","288/288 [==============================] - 0s 172us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 217us/step - loss: 2.9249 - accuracy: 0.7200\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 1.9934 - accuracy: 0.9383\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 51us/step - loss: 1.6818 - accuracy: 0.9661\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 1.4459 - accuracy: 0.9722\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 1.2544 - accuracy: 0.9835\n","287/287 [==============================] - 0s 168us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 213us/step - loss: 2.8904 - accuracy: 0.7357\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 1.9189 - accuracy: 0.9583\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 1.6277 - accuracy: 0.9730\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 51us/step - loss: 1.3904 - accuracy: 0.9791\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 61us/step - loss: 1.1975 - accuracy: 0.9896\n","287/287 [==============================] - 0s 165us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 217us/step - loss: 2.9251 - accuracy: 0.7209\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 1.9782 - accuracy: 0.9504\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 1.6669 - accuracy: 0.9783\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 1.4306 - accuracy: 0.9843\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 1.2328 - accuracy: 0.9878\n","287/287 [==============================] - 0s 165us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 203us/step - loss: 1.1333 - accuracy: 0.7363\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 53us/step - loss: 0.3961 - accuracy: 0.9513\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 0.3208 - accuracy: 0.9678\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 0.2806 - accuracy: 0.9791\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 53us/step - loss: 0.2666 - accuracy: 0.9809\n","288/288 [==============================] - 0s 157us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 201us/step - loss: 1.0971 - accuracy: 0.7450\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 59us/step - loss: 0.3803 - accuracy: 0.9495\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 52us/step - loss: 0.3164 - accuracy: 0.9695\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 49us/step - loss: 0.2719 - accuracy: 0.9826\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 51us/step - loss: 0.2572 - accuracy: 0.9809\n","288/288 [==============================] - 0s 155us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 197us/step - loss: 1.1036 - accuracy: 0.7330\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 0.4094 - accuracy: 0.9443\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 0.3301 - accuracy: 0.9678\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 54us/step - loss: 0.2831 - accuracy: 0.9791\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 0.2589 - accuracy: 0.9870\n","287/287 [==============================] - 0s 157us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 194us/step - loss: 1.1105 - accuracy: 0.7322\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 0.4094 - accuracy: 0.9461\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 51us/step - loss: 0.3396 - accuracy: 0.9565\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 49us/step - loss: 0.2968 - accuracy: 0.9678\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 50us/step - loss: 0.2586 - accuracy: 0.9852\n","287/287 [==============================] - 0s 171us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 219us/step - loss: 1.1805 - accuracy: 0.7009\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 0.4039 - accuracy: 0.9504\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 54us/step - loss: 0.3194 - accuracy: 0.9687\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 53us/step - loss: 0.2701 - accuracy: 0.9817\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 52us/step - loss: 0.2544 - accuracy: 0.9843\n","287/287 [==============================] - 0s 177us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 209us/step - loss: 8.9421 - accuracy: 0.2646\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 6.4555 - accuracy: 0.6710\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 45us/step - loss: 4.8762 - accuracy: 0.7946\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 3.7244 - accuracy: 0.8547\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 2.8567 - accuracy: 0.8999\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 2.2370 - accuracy: 0.9121\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 46us/step - loss: 1.7606 - accuracy: 0.9373\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.4045 - accuracy: 0.9469\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.1464 - accuracy: 0.9521\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.9604 - accuracy: 0.9617\n","288/288 [==============================] - 0s 180us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 211us/step - loss: 8.7850 - accuracy: 0.2968\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 6.3961 - accuracy: 0.6989\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 4.8214 - accuracy: 0.8468\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 3.6786 - accuracy: 0.8973\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 2.8337 - accuracy: 0.9234\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 2.2136 - accuracy: 0.9408\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.7532 - accuracy: 0.9487\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 1.4114 - accuracy: 0.9574\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 51us/step - loss: 1.1537 - accuracy: 0.9634\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 47us/step - loss: 0.9742 - accuracy: 0.9634\n","288/288 [==============================] - 0s 174us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 218us/step - loss: 8.9320 - accuracy: 0.3304\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 6.5368 - accuracy: 0.6391\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 4.9884 - accuracy: 0.7843\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 3.8424 - accuracy: 0.8626\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 2.9988 - accuracy: 0.8948\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 2.3732 - accuracy: 0.9200\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 1.9101 - accuracy: 0.9443\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.5734 - accuracy: 0.9417\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.3030 - accuracy: 0.9539\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.1125 - accuracy: 0.9496\n","287/287 [==============================] - 0s 184us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 214us/step - loss: 8.6776 - accuracy: 0.2652\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 6.3032 - accuracy: 0.6470\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 4.7643 - accuracy: 0.8052\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 3.6551 - accuracy: 0.8626\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 2.8310 - accuracy: 0.9043\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 2.2172 - accuracy: 0.9270\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.7736 - accuracy: 0.9443\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.4320 - accuracy: 0.9565\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.1887 - accuracy: 0.9548\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.0020 - accuracy: 0.9609\n","287/287 [==============================] - 0s 177us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 207us/step - loss: 8.8582 - accuracy: 0.3991\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 6.5726 - accuracy: 0.7270\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 5.0422 - accuracy: 0.8409\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 3.8799 - accuracy: 0.8904\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 3.0191 - accuracy: 0.9087\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 2.3677 - accuracy: 0.9278\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 1.9056 - accuracy: 0.9374\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.5337 - accuracy: 0.9574\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.2718 - accuracy: 0.9583\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.0678 - accuracy: 0.9696\n","287/287 [==============================] - 0s 180us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 197us/step - loss: 2.8760 - accuracy: 0.2689\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 1.7878 - accuracy: 0.6545\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 1.3703 - accuracy: 0.8077\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 50us/step - loss: 1.1213 - accuracy: 0.8834\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.9797 - accuracy: 0.9025\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.8751 - accuracy: 0.9295\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.8120 - accuracy: 0.9356\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.7434 - accuracy: 0.9478\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.6992 - accuracy: 0.9478\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.6500 - accuracy: 0.9617\n","288/288 [==============================] - 0s 164us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 193us/step - loss: 2.7692 - accuracy: 0.3020\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.7568 - accuracy: 0.7058\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.3216 - accuracy: 0.8294\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 1.0937 - accuracy: 0.8808\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.9605 - accuracy: 0.9095\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.8489 - accuracy: 0.9339\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.7830 - accuracy: 0.9408\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.7210 - accuracy: 0.9556\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 58us/step - loss: 0.6619 - accuracy: 0.9626\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.6359 - accuracy: 0.9600\n","288/288 [==============================] - 0s 153us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 186us/step - loss: 2.5565 - accuracy: 0.3800\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.5890 - accuracy: 0.7261\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.2163 - accuracy: 0.8409\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.0036 - accuracy: 0.8852\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.8897 - accuracy: 0.9070\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.7865 - accuracy: 0.9391\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.7193 - accuracy: 0.9374\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.6634 - accuracy: 0.9565\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.6153 - accuracy: 0.9583\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5816 - accuracy: 0.9591\n","287/287 [==============================] - 0s 165us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 223us/step - loss: 2.5065 - accuracy: 0.4191\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 1.6444 - accuracy: 0.7470\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.2409 - accuracy: 0.8661\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.0278 - accuracy: 0.9017\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.8987 - accuracy: 0.9313\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.8196 - accuracy: 0.9461\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.7345 - accuracy: 0.9565\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.6914 - accuracy: 0.9626\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.6264 - accuracy: 0.9713\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5974 - accuracy: 0.9696\n","287/287 [==============================] - 0s 169us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 209us/step - loss: 2.5278 - accuracy: 0.3887\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.5533 - accuracy: 0.7609\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 46us/step - loss: 1.2018 - accuracy: 0.8643\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.9922 - accuracy: 0.9209\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.8721 - accuracy: 0.9330\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.7929 - accuracy: 0.9426\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.7174 - accuracy: 0.9539\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.6636 - accuracy: 0.9635\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.6097 - accuracy: 0.9670\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5797 - accuracy: 0.9626\n","287/287 [==============================] - 0s 186us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 230us/step - loss: 2.2384 - accuracy: 0.2698\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.2562 - accuracy: 0.6362\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.7941 - accuracy: 0.8442\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.5813 - accuracy: 0.8755\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.4551 - accuracy: 0.9104\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 46us/step - loss: 0.3734 - accuracy: 0.9243\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.3130 - accuracy: 0.9382\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.2806 - accuracy: 0.9452\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 46us/step - loss: 0.2578 - accuracy: 0.9460\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 47us/step - loss: 0.2208 - accuracy: 0.9652\n","288/288 [==============================] - 0s 180us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 220us/step - loss: 2.1716 - accuracy: 0.3246\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.1948 - accuracy: 0.6815\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.8120 - accuracy: 0.8198\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.6169 - accuracy: 0.8712\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.4943 - accuracy: 0.8999\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.3954 - accuracy: 0.9295\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.3424 - accuracy: 0.9312\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 48us/step - loss: 0.2921 - accuracy: 0.9469\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 51us/step - loss: 0.2662 - accuracy: 0.9539\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 56us/step - loss: 0.2462 - accuracy: 0.9634\n","288/288 [==============================] - 0s 169us/step\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-06ed0be255d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hidden_size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'reg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                     **self._function_kwargs)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   3007\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[1;32m   3008\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3009\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   3823\u001b[0m       raise ValueError('Session keyword arguments are not support during '\n\u001b[1;32m   3824\u001b[0m                        'eager execution. You passed: %s' % (kwargs,))\n\u001b[0;32m-> 3825\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mEagerExecutionFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name)\u001b[0m\n\u001b[1;32m   3720\u001b[0m             \u001b[0madd_sources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3721\u001b[0m             \u001b[0mhandle_captures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3722\u001b[0;31m             base_graph=source_graph)\n\u001b[0m\u001b[1;32m   3723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3724\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlifted_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/lift_to_graph.py\u001b[0m in \u001b[0;36mlift_to_graph\u001b[0;34m(tensors, graph, sources, disallowed_placeholders, add_sources, handle_captures, base_graph, op_map)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m       new_input_mutations, new_control_mutations = _copy_non_source(\n\u001b[0;32m--> 339\u001b[0;31m           op=op, graph=graph, op_map=op_map, base_graph=base_graph)\n\u001b[0m\u001b[1;32m    340\u001b[0m       \u001b[0minput_mutations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input_mutations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0mcontrol_mutations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_control_mutations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/lift_to_graph.py\u001b[0m in \u001b[0;36m_copy_non_source\u001b[0;34m(op, graph, op_map, base_graph)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_tpu_replicate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         },  # b/128981532.\n\u001b[0;32m--> 134\u001b[0;31m         name=op.name)\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0mop_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopied_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3256\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3257\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3258\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m   def _create_op_internal(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3310\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3312\u001b[0;31m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_NodeDef\u001b[0;34m(op_type, name, attrs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m       \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"6elCaIQoUepe","colab_type":"text"},"source":["## Summary of results The best model seems to have 10 epochs a hidden layer size of 32 and an L2 regularizer of 0.01. As expected more epochs tend to lead to better results"]},{"cell_type":"code","metadata":{"id":"OTYw3wp8Udcx","colab_type":"code","outputId":"a391541e-b4f4-4851-890e-c83eb298c70c","executionInfo":{"status":"ok","timestamp":1587834790813,"user_tz":240,"elapsed":532,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":824}},"source":["res = pd.DataFrame(grid.cv_results_)\n","res.pivot_table(index=['param_epochs','param_hidden_size','param_reg'],values=['mean_test_score','rank_test_score'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>mean_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","    <tr>\n","      <th>param_epochs</th>\n","      <th>param_hidden_size</th>\n","      <th>param_reg</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"12\" valign=\"top\">5</th>\n","      <th rowspan=\"3\" valign=\"top\">32</th>\n","      <th>0.001</th>\n","      <td>0.886571</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.858694</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.872648</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">48</th>\n","      <th>0.001</th>\n","      <td>0.908815</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.911605</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.914382</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">64</th>\n","      <th>0.001</th>\n","      <td>0.932470</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.942235</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.938734</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">128</th>\n","      <th>0.001</th>\n","      <td>0.949891</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.949889</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.950588</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"12\" valign=\"top\">10</th>\n","      <th rowspan=\"3\" valign=\"top\">32</th>\n","      <th>0.001</th>\n","      <td>0.924843</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.930410</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.924826</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">48</th>\n","      <th>0.001</th>\n","      <td>0.947113</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.949206</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.939458</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">64</th>\n","      <th>0.001</th>\n","      <td>0.951273</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.959638</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.944309</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">128</th>\n","      <th>0.001</th>\n","      <td>0.963804</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.967978</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.956843</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          mean_test_score  rank_test_score\n","param_epochs param_hidden_size param_reg                                  \n","5            32                0.001             0.886571               22\n","                               0.010             0.858694               24\n","                               0.100             0.872648               23\n","             48                0.001             0.908815               21\n","                               0.010             0.911605               20\n","                               0.100             0.914382               19\n","             64                0.001             0.932470               15\n","                               0.010             0.942235               12\n","                               0.100             0.938734               14\n","             128               0.001             0.949891                7\n","                               0.010             0.949889                8\n","                               0.100             0.950588                6\n","10           32                0.001             0.924843               17\n","                               0.010             0.930410               16\n","                               0.100             0.924826               18\n","             48                0.001             0.947113               10\n","                               0.010             0.949206                9\n","                               0.100             0.939458               13\n","             64                0.001             0.951273                5\n","                               0.010             0.959638                3\n","                               0.100             0.944309               11\n","             128               0.001             0.963804                2\n","                               0.010             0.967978                1\n","                               0.100             0.956843                4"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Apy1PsxoSMt1","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"2qPyveL8RRJE","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Ynwl5O4QiMa9","colab_type":"code","outputId":"0543d892-dd28-421c-ad4e-88c2f7684b75","executionInfo":{"status":"ok","timestamp":1587793593568,"user_tz":240,"elapsed":1743,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.reshape(60000, 784)\n","X_test = X_test.reshape(10000, 784)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')\n","num_classes = 10\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n","60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y6PqwsUCRBjr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9Ca31kHe9QQ","colab_type":"code","colab":{}},"source":["model = Sequential([\n","    Dense(32, input_shape=(784,)),\n","    Activation('relu'),\n","    Dense(10),\n","    Activation('softmax')])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRyw4KGeiILP","colab_type":"code","colab":{}},"source":["model.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYyb7oj5klu3","colab_type":"code","colab":{}},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHaZf3c4ktiN","colab_type":"code","outputId":"168faa69-6f6d-4873-cffa-8dd91f0d483d","executionInfo":{"status":"ok","timestamp":1587738269562,"user_tz":240,"elapsed":745,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"tWHMbo0aiPJj","colab_type":"code","outputId":"0523e696-31ef-4534-a497-ca2ba9787631","executionInfo":{"status":"ok","timestamp":1587737625150,"user_tz":240,"elapsed":10277,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","60000/60000 [==============================] - 1s 19us/step - loss: 0.5024 - accuracy: 0.8645\n","Epoch 2/10\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2589 - accuracy: 0.9266\n","Epoch 3/10\n","60000/60000 [==============================] - 1s 15us/step - loss: 0.2167 - accuracy: 0.9385\n","Epoch 4/10\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.1870 - accuracy: 0.9465\n","Epoch 5/10\n","60000/60000 [==============================] - 1s 15us/step - loss: 0.1648 - accuracy: 0.9526\n","Epoch 6/10\n","60000/60000 [==============================] - 1s 15us/step - loss: 0.1492 - accuracy: 0.9570\n","Epoch 7/10\n","60000/60000 [==============================] - 1s 15us/step - loss: 0.1362 - accuracy: 0.9609\n","Epoch 8/10\n","60000/60000 [==============================] - 1s 15us/step - loss: 0.1245 - accuracy: 0.9641\n","Epoch 9/10\n","60000/60000 [==============================] - 1s 15us/step - loss: 0.1144 - accuracy: 0.9667\n","Epoch 10/10\n","60000/60000 [==============================] - 1s 15us/step - loss: 0.1055 - accuracy: 0.9691\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f6035b87780>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"FX5QNJrPiVnn","colab_type":"code","outputId":"7bf882e7-f8d7-4bbd-f9a7-595234344f95","executionInfo":{"status":"ok","timestamp":1587737647799,"user_tz":240,"elapsed":849,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["score = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Test loss: {:.3f}\".format(score[0]))\n","print(\"Test Accuracy: {:.3f}\".format(score[1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test loss: 0.134\n","Test Accuracy: 0.959\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"47RpqqKLidc1","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_digits\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9d_cWy1jzgB","colab_type":"code","colab":{}},"source":["digits = load_digits()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wq3uwq4olClH","colab_type":"code","outputId":"52bc4d60-d3f0-4f53-e37a-b0e906594d7c","executionInfo":{"status":"ok","timestamp":1587738364101,"user_tz":240,"elapsed":674,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["digits.data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1797, 64)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"bWWm0ZKJj1qx","colab_type":"code","outputId":"f1100fa2-018d-4ab9-9531-c696bc9e17f3","executionInfo":{"status":"ok","timestamp":1587738095473,"user_tz":240,"elapsed":686,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["plt.matshow(digits.images[0])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f6025d366d8>"]},"metadata":{"tags":[]},"execution_count":15},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"QCRxetlgj5Qg","colab_type":"code","outputId":"532babbd-d0f7-412f-aece-cd63bf1e201e","executionInfo":{"status":"ok","timestamp":1587794754457,"user_tz":240,"elapsed":405,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["X = digits.data\n","y = digits.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","# X_train /= 255\n","# X_test /= 255\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')\n","num_classes = 10\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1437 train samples\n","360 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bljeICidnDMu","colab_type":"code","colab":{}},"source":["model = Sequential([\n","Dense(32, input_shape=(64,),kernel_regularizer=regularizers.l2(0.1), bias_regularizer=regularizers.l2(0.01)), Activation('relu'), Dense(10), Activation('softmax')])\n","model.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y6x1CGU3sJiH","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"BlJAVwm4nT4A","colab_type":"code","outputId":"1583d062-9953-4b92-ed96-b3b3215c2df0","executionInfo":{"status":"ok","timestamp":1587739747479,"user_tz":240,"elapsed":826,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1437/1437 [==============================] - 0s 50us/step - loss: 51.1114 - accuracy: 0.1399\n","Epoch 2/10\n","1437/1437 [==============================] - 0s 11us/step - loss: 43.1980 - accuracy: 0.1573\n","Epoch 3/10\n","1437/1437 [==============================] - 0s 17us/step - loss: 37.0504 - accuracy: 0.1740\n","Epoch 4/10\n","1437/1437 [==============================] - 0s 11us/step - loss: 32.0914 - accuracy: 0.2331\n","Epoch 5/10\n","1437/1437 [==============================] - 0s 12us/step - loss: 27.8381 - accuracy: 0.3257\n","Epoch 6/10\n","1437/1437 [==============================] - 0s 12us/step - loss: 24.1563 - accuracy: 0.3953\n","Epoch 7/10\n","1437/1437 [==============================] - 0s 12us/step - loss: 20.9502 - accuracy: 0.4836\n","Epoch 8/10\n","1437/1437 [==============================] - 0s 11us/step - loss: 18.1573 - accuracy: 0.5685\n","Epoch 9/10\n","1437/1437 [==============================] - 0s 11us/step - loss: 15.7376 - accuracy: 0.6409\n","Epoch 10/10\n","1437/1437 [==============================] - 0s 12us/step - loss: 13.6348 - accuracy: 0.6973\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f6024a737f0>"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"y_C-W7qNnWFw","colab_type":"code","outputId":"f1d19682-6b14-4467-8ef0-042bd06b7bd3","executionInfo":{"status":"ok","timestamp":1587739279718,"user_tz":240,"elapsed":1171,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=.1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 1293 samples, validate on 144 samples\n","Epoch 1/10\n","1293/1293 [==============================] - 0s 17us/step - loss: 0.1343 - accuracy: 0.9637 - val_loss: 0.1486 - val_accuracy: 0.9583\n","Epoch 2/10\n","1293/1293 [==============================] - 0s 16us/step - loss: 0.1287 - accuracy: 0.9683 - val_loss: 0.1478 - val_accuracy: 0.9583\n","Epoch 3/10\n","1293/1293 [==============================] - 0s 14us/step - loss: 0.1244 - accuracy: 0.9698 - val_loss: 0.1456 - val_accuracy: 0.9583\n","Epoch 4/10\n","1293/1293 [==============================] - 0s 14us/step - loss: 0.1218 - accuracy: 0.9683 - val_loss: 0.1446 - val_accuracy: 0.9583\n","Epoch 5/10\n","1293/1293 [==============================] - 0s 16us/step - loss: 0.1171 - accuracy: 0.9753 - val_loss: 0.1471 - val_accuracy: 0.9583\n","Epoch 6/10\n","1293/1293 [==============================] - 0s 17us/step - loss: 0.1174 - accuracy: 0.9729 - val_loss: 0.1510 - val_accuracy: 0.9583\n","Epoch 7/10\n","1293/1293 [==============================] - 0s 17us/step - loss: 0.1105 - accuracy: 0.9791 - val_loss: 0.1395 - val_accuracy: 0.9514\n","Epoch 8/10\n","1293/1293 [==============================] - 0s 14us/step - loss: 0.1067 - accuracy: 0.9799 - val_loss: 0.1417 - val_accuracy: 0.9583\n","Epoch 9/10\n","1293/1293 [==============================] - 0s 14us/step - loss: 0.1061 - accuracy: 0.9745 - val_loss: 0.1447 - val_accuracy: 0.9514\n","Epoch 10/10\n","1293/1293 [==============================] - 0s 17us/step - loss: 0.1015 - accuracy: 0.9791 - val_loss: 0.1354 - val_accuracy: 0.9514\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f602501a668>"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"kAOiDZzIooun","colab_type":"code","colab":{}},"source":["from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n","from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZdSp5kvr7eC","colab_type":"code","colab":{}},"source":["def make_model(optimizer=\"adam\",hidden_size=32,reg = 0.01):\n","  model = Sequential([Dense(hidden_size, input_shape=(64,),kernel_regularizer=regularizers.l2(reg), bias_regularizer=regularizers.l2(reg)), Activation('relu'), Dense(10), Activation('softmax')])\n","  model.compile(optimizer = optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy']) \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UnzFE3ehshD4","colab_type":"code","colab":{}},"source":["clf = KerasClassifier(make_model)\n","param_grid = {'epochs': [1,5,10], 'hidden_size':[32,64,256],'reg': [1,0.1,0.01,0.001]}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_b7sQTccs-AF","colab_type":"code","outputId":"f43edaa0-c1c3-4867-b302-e4f32747d80a","executionInfo":{"status":"ok","timestamp":1587741465141,"user_tz":240,"elapsed":148093,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["clf = KerasClassifier(make_model)\n","param_grid = {'epochs': [1,5,10], 'hidden_size':[32,64,256],'reg': [1,0.1,0.01,0.001]}\n","grid = GridSearchCV(clf,param_grid=param_grid)\n","grid.fit(X_train,y_train)\n","import pandas as pd\n","res = pd.DataFrame(grid.cv_results_)\n","res.pivot_table(index=['param_epochs','param_hidden_size','param_reg'],values=['mean_test_score','rank_test_score'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/1\n","1149/1149 [==============================] - 0s 91us/step - loss: 43.0608 - accuracy: 0.1062\n","288/288 [==============================] - 0s 91us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 86us/step - loss: 44.2915 - accuracy: 0.1558\n","288/288 [==============================] - 0s 93us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 82us/step - loss: 45.5515 - accuracy: 0.0861\n","287/287 [==============================] - 0s 82us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 87us/step - loss: 42.3806 - accuracy: 0.1357\n","287/287 [==============================] - 0s 97us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 81us/step - loss: 44.3404 - accuracy: 0.1574\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 94us/step - loss: 9.0833 - accuracy: 0.1732\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 92us/step - loss: 10.9819 - accuracy: 0.1462\n","288/288 [==============================] - 0s 112us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 93us/step - loss: 12.3635 - accuracy: 0.1678\n","287/287 [==============================] - 0s 93us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 88us/step - loss: 11.6880 - accuracy: 0.0887\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 88us/step - loss: 11.5433 - accuracy: 0.0878\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 88us/step - loss: 7.8757 - accuracy: 0.1854\n","288/288 [==============================] - 0s 88us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 97us/step - loss: 7.0329 - accuracy: 0.1366\n","288/288 [==============================] - 0s 92us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 87us/step - loss: 5.9136 - accuracy: 0.1626\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 96us/step - loss: 5.5074 - accuracy: 0.2296\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 94us/step - loss: 10.9331 - accuracy: 0.1443\n","287/287 [==============================] - 0s 97us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 91us/step - loss: 5.6263 - accuracy: 0.1662\n","288/288 [==============================] - 0s 87us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 90us/step - loss: 5.4107 - accuracy: 0.1540\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 91us/step - loss: 4.3535 - accuracy: 0.2165\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 96us/step - loss: 3.5516 - accuracy: 0.2878\n","287/287 [==============================] - 0s 98us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 92us/step - loss: 7.3392 - accuracy: 0.1817\n","287/287 [==============================] - 0s 100us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 89us/step - loss: 59.3216 - accuracy: 0.2585\n","288/288 [==============================] - 0s 90us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 88us/step - loss: 56.8717 - accuracy: 0.2637\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 94us/step - loss: 57.7926 - accuracy: 0.2878\n","287/287 [==============================] - 0s 88us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 84us/step - loss: 60.4404 - accuracy: 0.1939\n","287/287 [==============================] - 0s 88us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 95us/step - loss: 57.0664 - accuracy: 0.2070\n","287/287 [==============================] - 0s 90us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 95us/step - loss: 9.3253 - accuracy: 0.3386\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 98us/step - loss: 9.8810 - accuracy: 0.2132\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 90us/step - loss: 9.5278 - accuracy: 0.3339\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 89us/step - loss: 9.2052 - accuracy: 0.3243\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 88us/step - loss: 11.9661 - accuracy: 0.2357\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 87us/step - loss: 5.1525 - accuracy: 0.2393\n","288/288 [==============================] - 0s 90us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 89us/step - loss: 2.8301 - accuracy: 0.4700\n","288/288 [==============================] - 0s 91us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 89us/step - loss: 4.4083 - accuracy: 0.2887\n","287/287 [==============================] - 0s 92us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 90us/step - loss: 4.9080 - accuracy: 0.2600\n","287/287 [==============================] - 0s 88us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 90us/step - loss: 4.4396 - accuracy: 0.2983\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 88us/step - loss: 5.2427 - accuracy: 0.2489\n","288/288 [==============================] - 0s 85us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 86us/step - loss: 4.6376 - accuracy: 0.2837\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 94us/step - loss: 5.2950 - accuracy: 0.1974\n","287/287 [==============================] - 0s 92us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 88us/step - loss: 5.2732 - accuracy: 0.2322\n","287/287 [==============================] - 0s 100us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 89us/step - loss: 5.4895 - accuracy: 0.2539\n","287/287 [==============================] - 0s 90us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 91us/step - loss: 75.4212 - accuracy: 0.5692\n","288/288 [==============================] - 0s 100us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 93us/step - loss: 77.5182 - accuracy: 0.4491\n","288/288 [==============================] - 0s 91us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 102us/step - loss: 76.3500 - accuracy: 0.4730\n","287/287 [==============================] - 0s 96us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 102us/step - loss: 75.6383 - accuracy: 0.4748\n","287/287 [==============================] - 0s 109us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 99us/step - loss: 76.9866 - accuracy: 0.5435\n","287/287 [==============================] - 0s 93us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 97us/step - loss: 10.5787 - accuracy: 0.5431\n","288/288 [==============================] - 0s 92us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 105us/step - loss: 10.4188 - accuracy: 0.5727\n","288/288 [==============================] - 0s 114us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 95us/step - loss: 9.9038 - accuracy: 0.6600\n","287/287 [==============================] - 0s 93us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 101us/step - loss: 10.8283 - accuracy: 0.5400\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 98us/step - loss: 11.7143 - accuracy: 0.4643\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 98us/step - loss: 2.5968 - accuracy: 0.6397\n","288/288 [==============================] - 0s 94us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 98us/step - loss: 3.0701 - accuracy: 0.5318\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 95us/step - loss: 2.5893 - accuracy: 0.5930\n","287/287 [==============================] - 0s 90us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 96us/step - loss: 3.0608 - accuracy: 0.5087\n","287/287 [==============================] - 0s 106us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 95us/step - loss: 3.1690 - accuracy: 0.5200\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 94us/step - loss: 1.3500 - accuracy: 0.6806\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/1\n","1149/1149 [==============================] - 0s 95us/step - loss: 1.7960 - accuracy: 0.5962\n","288/288 [==============================] - 0s 94us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 93us/step - loss: 1.8418 - accuracy: 0.5948\n","287/287 [==============================] - 0s 93us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 96us/step - loss: 2.5393 - accuracy: 0.5313\n","287/287 [==============================] - 0s 112us/step\n","Epoch 1/1\n","1150/1150 [==============================] - 0s 90us/step - loss: 2.0002 - accuracy: 0.5983\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 89us/step - loss: 41.1418 - accuracy: 0.1453\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 26.9049 - accuracy: 0.3586\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 18.0521 - accuracy: 0.5205\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 12.1205 - accuracy: 0.6249\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 8.0878 - accuracy: 0.7528\n","288/288 [==============================] - 0s 85us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 89us/step - loss: 40.3285 - accuracy: 0.1784\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 26.4326 - accuracy: 0.3307\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 17.5707 - accuracy: 0.5065\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 11.6860 - accuracy: 0.6449\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 32us/step - loss: 7.7329 - accuracy: 0.7720\n","288/288 [==============================] - 0s 87us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 84us/step - loss: 44.5567 - accuracy: 0.1496\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 29.0406 - accuracy: 0.3478\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 37us/step - loss: 19.7060 - accuracy: 0.5774\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 13.5091 - accuracy: 0.7191\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 9.2751 - accuracy: 0.8070\n","287/287 [==============================] - 0s 90us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 86us/step - loss: 39.9556 - accuracy: 0.1478\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 26.0182 - accuracy: 0.3287\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 17.3913 - accuracy: 0.5400\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 11.6166 - accuracy: 0.7417\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 7.7891 - accuracy: 0.8348\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 97us/step - loss: 44.1710 - accuracy: 0.1122\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 28.6199 - accuracy: 0.2913\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 19.3886 - accuracy: 0.5200\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 13.1554 - accuracy: 0.6774\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 8.8965 - accuracy: 0.7713\n","287/287 [==============================] - 0s 106us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 92us/step - loss: 8.8888 - accuracy: 0.1828\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 5.2494 - accuracy: 0.4439\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 3.8456 - accuracy: 0.6780\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 3.1113 - accuracy: 0.7929\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.6267 - accuracy: 0.8503\n","288/288 [==============================] - 0s 94us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 96us/step - loss: 9.1175 - accuracy: 0.1775\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 5.6408 - accuracy: 0.4117\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 4.1457 - accuracy: 0.6075\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 3.2996 - accuracy: 0.7389\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.7505 - accuracy: 0.7920\n","288/288 [==============================] - 0s 91us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 88us/step - loss: 8.7232 - accuracy: 0.1322\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 5.2515 - accuracy: 0.4174\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 4.0021 - accuracy: 0.6139\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.2351 - accuracy: 0.7513\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 37us/step - loss: 2.6899 - accuracy: 0.8243\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 90us/step - loss: 8.7798 - accuracy: 0.1826\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 4.8773 - accuracy: 0.4678\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 3.5935 - accuracy: 0.7096\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 2.9044 - accuracy: 0.7965\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.4326 - accuracy: 0.8635\n","287/287 [==============================] - 0s 101us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 89us/step - loss: 10.6184 - accuracy: 0.2183\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 5.4887 - accuracy: 0.4261\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 4.0101 - accuracy: 0.6452\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.2879 - accuracy: 0.7452\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.7963 - accuracy: 0.8104\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 92us/step - loss: 7.2900 - accuracy: 0.1001\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.9377 - accuracy: 0.3429\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 38us/step - loss: 1.7353 - accuracy: 0.5997\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.2466 - accuracy: 0.7267\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.9810 - accuracy: 0.7920\n","288/288 [==============================] - 0s 92us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 89us/step - loss: 6.6720 - accuracy: 0.1889\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 2.8670 - accuracy: 0.4386\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.6057 - accuracy: 0.6292\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.0588 - accuracy: 0.7728\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 37us/step - loss: 0.8218 - accuracy: 0.8425\n","288/288 [==============================] - 0s 103us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 108us/step - loss: 7.5902 - accuracy: 0.1270\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.9347 - accuracy: 0.3226\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 36us/step - loss: 1.7173 - accuracy: 0.5687\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 1.1982 - accuracy: 0.7052\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 0.9347 - accuracy: 0.7974\n","287/287 [==============================] - 0s 101us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 89us/step - loss: 6.7577 - accuracy: 0.1739\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 2.5138 - accuracy: 0.4383\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.4749 - accuracy: 0.6591\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.0957 - accuracy: 0.7478\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.8813 - accuracy: 0.8209\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 91us/step - loss: 8.7176 - accuracy: 0.1452\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.9334 - accuracy: 0.3870\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 38us/step - loss: 1.7222 - accuracy: 0.5783\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.2659 - accuracy: 0.7078\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.0361 - accuracy: 0.7748\n","287/287 [==============================] - 0s 108us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 86us/step - loss: 5.8857 - accuracy: 0.1993\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.9727 - accuracy: 0.4970\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.1123 - accuracy: 0.6701\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.8180 - accuracy: 0.7598\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 32us/step - loss: 0.6512 - accuracy: 0.8103\n","288/288 [==============================] - 0s 93us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 88us/step - loss: 4.4732 - accuracy: 0.1628\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 36us/step - loss: 1.7083 - accuracy: 0.4935\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.9637 - accuracy: 0.6823\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.6666 - accuracy: 0.7937\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.5053 - accuracy: 0.8468\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 85us/step - loss: 7.3801 - accuracy: 0.2313\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 2.3750 - accuracy: 0.4365\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 38us/step - loss: 1.3258 - accuracy: 0.6252\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.9123 - accuracy: 0.7287\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.6821 - accuracy: 0.8096\n","287/287 [==============================] - 0s 97us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 86us/step - loss: 8.1416 - accuracy: 0.1704\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 2.6371 - accuracy: 0.4061\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.4565 - accuracy: 0.5643\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.9698 - accuracy: 0.6835\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.7008 - accuracy: 0.7687\n","287/287 [==============================] - 0s 88us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 88us/step - loss: 6.6283 - accuracy: 0.1922\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 2.4237 - accuracy: 0.4304\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.3775 - accuracy: 0.6278\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 0.9445 - accuracy: 0.7278\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 32us/step - loss: 0.7115 - accuracy: 0.7983\n","287/287 [==============================] - 0s 98us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 90us/step - loss: 60.2672 - accuracy: 0.2454\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 37.3320 - accuracy: 0.5796\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 23.5508 - accuracy: 0.7789\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 14.7173 - accuracy: 0.8547\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 9.1234 - accuracy: 0.8990\n","288/288 [==============================] - 0s 110us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 89us/step - loss: 57.8792 - accuracy: 0.2263\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 35.5005 - accuracy: 0.6144\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 21.8772 - accuracy: 0.8016\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 13.2974 - accuracy: 0.8616\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 8.0181 - accuracy: 0.8973\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 84us/step - loss: 59.7866 - accuracy: 0.2096\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 37.4025 - accuracy: 0.4991\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 23.9625 - accuracy: 0.7304\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 38us/step - loss: 15.2262 - accuracy: 0.8391\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 9.6128 - accuracy: 0.8861\n","287/287 [==============================] - 0s 85us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 85us/step - loss: 57.3432 - accuracy: 0.2287\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 35.1673 - accuracy: 0.6104\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 21.7412 - accuracy: 0.7835\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 13.3015 - accuracy: 0.8565\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 8.0735 - accuracy: 0.8939\n","287/287 [==============================] - 0s 97us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 97us/step - loss: 58.3625 - accuracy: 0.2191\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 36.1776 - accuracy: 0.5817\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 22.3702 - accuracy: 0.7617\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 13.6129 - accuracy: 0.8478\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 38us/step - loss: 8.2021 - accuracy: 0.9026\n","287/287 [==============================] - 0s 104us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 116us/step - loss: 12.2941 - accuracy: 0.1245\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 6.1911 - accuracy: 0.5701\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 4.5948 - accuracy: 0.7998\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 3.7644 - accuracy: 0.8799\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 38us/step - loss: 3.2002 - accuracy: 0.9173\n","288/288 [==============================] - 0s 99us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 95us/step - loss: 11.0241 - accuracy: 0.1880\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 6.1041 - accuracy: 0.5840\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 4.5036 - accuracy: 0.7755\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 33us/step - loss: 3.6034 - accuracy: 0.8660\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 2.9955 - accuracy: 0.8921\n","288/288 [==============================] - 0s 94us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 92us/step - loss: 9.0289 - accuracy: 0.3470\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 5.3989 - accuracy: 0.7687\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 4.2048 - accuracy: 0.8791\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 3.4318 - accuracy: 0.9087\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.8644 - accuracy: 0.9304\n","287/287 [==============================] - 0s 105us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 89us/step - loss: 9.9612 - accuracy: 0.2591\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 36us/step - loss: 5.6944 - accuracy: 0.7217\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 4.4089 - accuracy: 0.8522\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 3.6069 - accuracy: 0.9009\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 3.0307 - accuracy: 0.9278\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 93us/step - loss: 11.3236 - accuracy: 0.1930\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 36us/step - loss: 6.0185 - accuracy: 0.6200\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 4.5611 - accuracy: 0.8035\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 3.7027 - accuracy: 0.8826\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.1124 - accuracy: 0.9243\n","287/287 [==============================] - 0s 96us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 96us/step - loss: 7.4259 - accuracy: 0.1575\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 2.2433 - accuracy: 0.5318\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.2255 - accuracy: 0.7668\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.9085 - accuracy: 0.8634\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.7597 - accuracy: 0.9008\n","288/288 [==============================] - 0s 101us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 89us/step - loss: 4.2412 - accuracy: 0.3020\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 37us/step - loss: 1.4574 - accuracy: 0.7137\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 36us/step - loss: 0.9831 - accuracy: 0.8442\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.7819 - accuracy: 0.9060\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.6683 - accuracy: 0.9295\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 93us/step - loss: 5.0449 - accuracy: 0.2661\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.6721 - accuracy: 0.6939\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.0831 - accuracy: 0.8313\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.8541 - accuracy: 0.8800\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.7309 - accuracy: 0.9139\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 88us/step - loss: 5.9532 - accuracy: 0.2157\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.8219 - accuracy: 0.5957\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.0890 - accuracy: 0.7983\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.8536 - accuracy: 0.8626\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.7023 - accuracy: 0.9087\n","287/287 [==============================] - 0s 98us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 92us/step - loss: 7.5559 - accuracy: 0.1557\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.2018 - accuracy: 0.5583\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.1886 - accuracy: 0.8174\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.8825 - accuracy: 0.8809\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.7506 - accuracy: 0.9148\n","287/287 [==============================] - 0s 102us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 88us/step - loss: 6.7916 - accuracy: 0.2202\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.3365 - accuracy: 0.6136\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.6571 - accuracy: 0.8155\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.4679 - accuracy: 0.8721\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.3717 - accuracy: 0.9060\n","288/288 [==============================] - 0s 101us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 88us/step - loss: 2.9598 - accuracy: 0.4030\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.7933 - accuracy: 0.8068\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.4459 - accuracy: 0.8886\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.3143 - accuracy: 0.9208\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.2354 - accuracy: 0.9530\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 88us/step - loss: 2.8291 - accuracy: 0.4200\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.8557 - accuracy: 0.7365\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.4859 - accuracy: 0.8591\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.3408 - accuracy: 0.9052\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.2551 - accuracy: 0.9296\n","287/287 [==============================] - 0s 101us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 86us/step - loss: 3.7796 - accuracy: 0.3217\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.0669 - accuracy: 0.7043\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.6097 - accuracy: 0.8374\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.4323 - accuracy: 0.8774\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.3367 - accuracy: 0.9104\n","287/287 [==============================] - 0s 106us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 87us/step - loss: 4.8805 - accuracy: 0.2470\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.0591 - accuracy: 0.6991\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.5488 - accuracy: 0.8452\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.3815 - accuracy: 0.8957\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 37us/step - loss: 0.2904 - accuracy: 0.9383\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 94us/step - loss: 77.3393 - accuracy: 0.5135\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 35.0478 - accuracy: 0.8790\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 45us/step - loss: 14.8255 - accuracy: 0.9243\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 6.0826 - accuracy: 0.9295\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 40us/step - loss: 2.5781 - accuracy: 0.9391\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 96us/step - loss: 76.3748 - accuracy: 0.5657\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 33.9907 - accuracy: 0.8825\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 14.0517 - accuracy: 0.9321\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 5.5990 - accuracy: 0.9452\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 2.3486 - accuracy: 0.9330\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 91us/step - loss: 76.3763 - accuracy: 0.5365\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 34.0839 - accuracy: 0.8757\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 14.2104 - accuracy: 0.9165\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 5.7397 - accuracy: 0.9330\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 2.4308 - accuracy: 0.9374\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 93us/step - loss: 77.0027 - accuracy: 0.4983\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 40us/step - loss: 34.3436 - accuracy: 0.8678\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 14.3654 - accuracy: 0.9322\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 5.8562 - accuracy: 0.9426\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 2.4722 - accuracy: 0.9470\n","287/287 [==============================] - 0s 92us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 103us/step - loss: 78.4240 - accuracy: 0.5252\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 35.3404 - accuracy: 0.9035\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 14.8914 - accuracy: 0.9270\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 6.0895 - accuracy: 0.9443\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 2.5759 - accuracy: 0.9539\n","287/287 [==============================] - 0s 114us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 105us/step - loss: 10.5209 - accuracy: 0.5440\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 46us/step - loss: 6.1597 - accuracy: 0.9060\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 40us/step - loss: 4.3436 - accuracy: 0.9661\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 3.2358 - accuracy: 0.9678\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 2.4902 - accuracy: 0.9756\n","288/288 [==============================] - 0s 102us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 99us/step - loss: 10.5262 - accuracy: 0.5596\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 6.3899 - accuracy: 0.9278\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 4.5813 - accuracy: 0.9643\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 3.4280 - accuracy: 0.9739\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 43us/step - loss: 2.6255 - accuracy: 0.9800\n","288/288 [==============================] - 0s 92us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 108us/step - loss: 10.6109 - accuracy: 0.5704\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 6.4105 - accuracy: 0.9139\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 4.5653 - accuracy: 0.9487\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 3.3964 - accuracy: 0.9696\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 2.6039 - accuracy: 0.9774\n","287/287 [==============================] - 0s 101us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 101us/step - loss: 10.7389 - accuracy: 0.5417\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 6.4830 - accuracy: 0.9096\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 49us/step - loss: 4.6854 - accuracy: 0.9574\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 40us/step - loss: 3.5311 - accuracy: 0.9730\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 2.7486 - accuracy: 0.9748\n","287/287 [==============================] - 0s 103us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 101us/step - loss: 10.5355 - accuracy: 0.5957\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 6.4066 - accuracy: 0.9296\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 4.5678 - accuracy: 0.9574\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 3.3874 - accuracy: 0.9774\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 2.5843 - accuracy: 0.9783\n","287/287 [==============================] - 0s 113us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 99us/step - loss: 2.7383 - accuracy: 0.5762\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 1.0414 - accuracy: 0.9295\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.8564 - accuracy: 0.9687\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.7744 - accuracy: 0.9765\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.7005 - accuracy: 0.9878\n","288/288 [==============================] - 0s 118us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 106us/step - loss: 2.5996 - accuracy: 0.6197\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 46us/step - loss: 1.0645 - accuracy: 0.9182\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.8666 - accuracy: 0.9530\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.7609 - accuracy: 0.9669\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.6833 - accuracy: 0.9843\n","288/288 [==============================] - 0s 100us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 102us/step - loss: 3.0993 - accuracy: 0.5452\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 1.0643 - accuracy: 0.9061\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.8625 - accuracy: 0.9470\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 54us/step - loss: 0.7586 - accuracy: 0.9704\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.6820 - accuracy: 0.9826\n","287/287 [==============================] - 0s 101us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 101us/step - loss: 2.7913 - accuracy: 0.5783\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 1.0034 - accuracy: 0.9374\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.8426 - accuracy: 0.9626\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.7442 - accuracy: 0.9783\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.6744 - accuracy: 0.9887\n","287/287 [==============================] - 0s 92us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 98us/step - loss: 2.6765 - accuracy: 0.5765\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.9995 - accuracy: 0.9383\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.8293 - accuracy: 0.9661\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.7295 - accuracy: 0.9843\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.6540 - accuracy: 0.9913\n","287/287 [==============================] - 0s 103us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 97us/step - loss: 2.3118 - accuracy: 0.5187\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.3744 - accuracy: 0.9095\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.2412 - accuracy: 0.9504\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 38us/step - loss: 0.1830 - accuracy: 0.9721\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.1519 - accuracy: 0.9852\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/5\n","1149/1149 [==============================] - 0s 99us/step - loss: 1.5798 - accuracy: 0.6423\n","Epoch 2/5\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.3213 - accuracy: 0.9260\n","Epoch 3/5\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.2299 - accuracy: 0.9600\n","Epoch 4/5\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.1731 - accuracy: 0.9756\n","Epoch 5/5\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.1406 - accuracy: 0.9878\n","288/288 [==============================] - 0s 93us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 96us/step - loss: 1.8813 - accuracy: 0.5713\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.3433 - accuracy: 0.9209\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.2182 - accuracy: 0.9617\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1749 - accuracy: 0.9739\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1386 - accuracy: 0.9843\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 116us/step - loss: 1.7349 - accuracy: 0.5861\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.3534 - accuracy: 0.9209\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.2227 - accuracy: 0.9600\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.1757 - accuracy: 0.9748\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.1466 - accuracy: 0.9861\n","287/287 [==============================] - 0s 96us/step\n","Epoch 1/5\n","1150/1150 [==============================] - 0s 95us/step - loss: 1.8817 - accuracy: 0.5713\n","Epoch 2/5\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.3031 - accuracy: 0.9322\n","Epoch 3/5\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.2052 - accuracy: 0.9670\n","Epoch 4/5\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.1610 - accuracy: 0.9783\n","Epoch 5/5\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.1335 - accuracy: 0.9913\n","287/287 [==============================] - 0s 98us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 89us/step - loss: 42.9159 - accuracy: 0.1819\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 28.4319 - accuracy: 0.3760\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 32us/step - loss: 19.4356 - accuracy: 0.5674\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 13.3430 - accuracy: 0.7032\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 32us/step - loss: 9.1703 - accuracy: 0.7868\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 6.3434 - accuracy: 0.8329\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 4.4386 - accuracy: 0.8695\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 3.1578 - accuracy: 0.8990\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.3081 - accuracy: 0.9182\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 1.7411 - accuracy: 0.9347\n","288/288 [==============================] - 0s 92us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 88us/step - loss: 40.8849 - accuracy: 0.2132\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 26.9853 - accuracy: 0.4308\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 32us/step - loss: 18.1923 - accuracy: 0.6371\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 32us/step - loss: 12.2446 - accuracy: 0.7398\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 8.2299 - accuracy: 0.8138\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 5.5501 - accuracy: 0.8547\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 3.7937 - accuracy: 0.8964\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.6417 - accuracy: 0.9112\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 1.9056 - accuracy: 0.9365\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 1.4260 - accuracy: 0.9434\n","288/288 [==============================] - 0s 106us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 83us/step - loss: 39.2181 - accuracy: 0.2609\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 25.8225 - accuracy: 0.4957\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 17.1361 - accuracy: 0.6826\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 11.3130 - accuracy: 0.7774\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 7.4321 - accuracy: 0.8478\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 4.8960 - accuracy: 0.8939\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.2742 - accuracy: 0.9087\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 2.2445 - accuracy: 0.9278\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.6052 - accuracy: 0.9322\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.1956 - accuracy: 0.9443\n","287/287 [==============================] - 0s 87us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 83us/step - loss: 43.4309 - accuracy: 0.1452\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 28.6314 - accuracy: 0.3374\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 19.3067 - accuracy: 0.5539\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 13.0653 - accuracy: 0.7078\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 8.8413 - accuracy: 0.8026\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 6.0140 - accuracy: 0.8539\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 4.1432 - accuracy: 0.8939\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 2.9154 - accuracy: 0.9139\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.1140 - accuracy: 0.9252\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.5979 - accuracy: 0.9270\n","287/287 [==============================] - 0s 108us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 83us/step - loss: 44.8169 - accuracy: 0.0852\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 28.8195 - accuracy: 0.2357\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 19.2946 - accuracy: 0.4504\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 13.0044 - accuracy: 0.6496\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 8.7772 - accuracy: 0.7826\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 5.9552 - accuracy: 0.8643\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 4.0902 - accuracy: 0.9209\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.8671 - accuracy: 0.9330\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 2.0651 - accuracy: 0.9426\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.5369 - accuracy: 0.9565\n","287/287 [==============================] - 0s 90us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 86us/step - loss: 10.1123 - accuracy: 0.1279\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 5.3885 - accuracy: 0.4369\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 4.0198 - accuracy: 0.6728\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 3.2750 - accuracy: 0.7755\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.7927 - accuracy: 0.8329\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.4290 - accuracy: 0.8721\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 2.1387 - accuracy: 0.9025\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.9087 - accuracy: 0.9173\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.7220 - accuracy: 0.9330\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 1.5673 - accuracy: 0.9426\n","288/288 [==============================] - 0s 90us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 100us/step - loss: 9.9810 - accuracy: 0.1384\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 5.9638 - accuracy: 0.3177\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 4.2221 - accuracy: 0.5814\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 3.3707 - accuracy: 0.7198\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 38us/step - loss: 2.8488 - accuracy: 0.7903\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.4614 - accuracy: 0.8399\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 38us/step - loss: 2.1682 - accuracy: 0.8816\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 1.9280 - accuracy: 0.9069\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.7272 - accuracy: 0.9234\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.5646 - accuracy: 0.9295\n","288/288 [==============================] - 0s 101us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 93us/step - loss: 13.9773 - accuracy: 0.1296\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 6.6673 - accuracy: 0.3330\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 4.5122 - accuracy: 0.6113\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 3.6660 - accuracy: 0.7409\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 3.1334 - accuracy: 0.8035\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.7413 - accuracy: 0.8557\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 2.4459 - accuracy: 0.8835\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 2.1900 - accuracy: 0.9157\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.9922 - accuracy: 0.9304\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.8199 - accuracy: 0.9426\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 92us/step - loss: 9.4559 - accuracy: 0.1652\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 5.5144 - accuracy: 0.3913\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 4.0017 - accuracy: 0.6278\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 3.2057 - accuracy: 0.7609\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 2.7000 - accuracy: 0.8374\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 2.3290 - accuracy: 0.8783\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 2.0522 - accuracy: 0.9087\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.8236 - accuracy: 0.9191\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.6489 - accuracy: 0.9322\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.4895 - accuracy: 0.9374\n","287/287 [==============================] - 0s 96us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 91us/step - loss: 8.9016 - accuracy: 0.2052\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 5.1189 - accuracy: 0.4591\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.8100 - accuracy: 0.7061\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.1256 - accuracy: 0.7913\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.6573 - accuracy: 0.8383\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 2.2883 - accuracy: 0.8809\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 2.0051 - accuracy: 0.9130\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.7897 - accuracy: 0.9191\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.6022 - accuracy: 0.9409\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.4547 - accuracy: 0.9557\n","287/287 [==============================] - 0s 110us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 90us/step - loss: 7.2099 - accuracy: 0.1288\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.6725 - accuracy: 0.3847\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.6406 - accuracy: 0.5770\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.2435 - accuracy: 0.6936\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 1.0020 - accuracy: 0.7755\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.8497 - accuracy: 0.8198\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.7418 - accuracy: 0.8607\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.6659 - accuracy: 0.8703\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.6049 - accuracy: 0.8973\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.5532 - accuracy: 0.9130\n","288/288 [==============================] - 0s 93us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 93us/step - loss: 6.5894 - accuracy: 0.1445\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.9058 - accuracy: 0.3377\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.9200 - accuracy: 0.5300\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.4359 - accuracy: 0.6414\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.1340 - accuracy: 0.7198\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.9172 - accuracy: 0.7911\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 0.7819 - accuracy: 0.8364\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.6768 - accuracy: 0.8721\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.5938 - accuracy: 0.8990\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.5318 - accuracy: 0.9269\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 95us/step - loss: 7.2061 - accuracy: 0.1487\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.7701 - accuracy: 0.3530\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.7475 - accuracy: 0.5783\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.2642 - accuracy: 0.7174\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.0167 - accuracy: 0.7739\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.8456 - accuracy: 0.8278\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.7260 - accuracy: 0.8617\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 0.6235 - accuracy: 0.8913\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.5589 - accuracy: 0.9113\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.5075 - accuracy: 0.9278\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 92us/step - loss: 7.2384 - accuracy: 0.1983\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.7447 - accuracy: 0.3817\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.4486 - accuracy: 0.6687\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.0722 - accuracy: 0.7696\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.8504 - accuracy: 0.8261\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.7031 - accuracy: 0.8748\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.6126 - accuracy: 0.9017\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 0.5398 - accuracy: 0.9278\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.4944 - accuracy: 0.9313\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.4545 - accuracy: 0.9443\n","287/287 [==============================] - 0s 100us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 88us/step - loss: 6.3768 - accuracy: 0.1148\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 2.7137 - accuracy: 0.3739\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.5144 - accuracy: 0.6200\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.0948 - accuracy: 0.7730\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.8701 - accuracy: 0.8383\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.7389 - accuracy: 0.8765\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.6577 - accuracy: 0.8896\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.5969 - accuracy: 0.9035\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.5409 - accuracy: 0.9183\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 0.5040 - accuracy: 0.9348\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 88us/step - loss: 6.2799 - accuracy: 0.1558\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 52us/step - loss: 2.5210 - accuracy: 0.4473\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.5008 - accuracy: 0.6040\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.0179 - accuracy: 0.7241\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.7569 - accuracy: 0.7859\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 32us/step - loss: 0.5870 - accuracy: 0.8277\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.4784 - accuracy: 0.8634\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.4026 - accuracy: 0.8842\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.3474 - accuracy: 0.9025\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 0.3038 - accuracy: 0.9121\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 96us/step - loss: 5.4808 - accuracy: 0.1775\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.3152 - accuracy: 0.3525\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 1.3045 - accuracy: 0.5997\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.8501 - accuracy: 0.7328\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.6003 - accuracy: 0.8103\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.4549 - accuracy: 0.8703\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.3667 - accuracy: 0.8930\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.3029 - accuracy: 0.9138\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.2613 - accuracy: 0.9286\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 0.2267 - accuracy: 0.9373\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 92us/step - loss: 7.9530 - accuracy: 0.0957\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.8732 - accuracy: 0.3026\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.5753 - accuracy: 0.5313\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.0390 - accuracy: 0.6870\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.7682 - accuracy: 0.7843\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.6024 - accuracy: 0.8226\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.4975 - accuracy: 0.8643\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.4199 - accuracy: 0.8783\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.3651 - accuracy: 0.8974\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.3256 - accuracy: 0.9043\n","287/287 [==============================] - 0s 113us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 89us/step - loss: 5.7371 - accuracy: 0.1322\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 2.3319 - accuracy: 0.3348\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.3122 - accuracy: 0.5730\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.8533 - accuracy: 0.7322\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.6302 - accuracy: 0.8043\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.4751 - accuracy: 0.8609\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.3764 - accuracy: 0.8922\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.3121 - accuracy: 0.9096\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.2679 - accuracy: 0.9243\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.2303 - accuracy: 0.9452\n","287/287 [==============================] - 0s 96us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 89us/step - loss: 4.4908 - accuracy: 0.2183\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.8111 - accuracy: 0.5296\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.9717 - accuracy: 0.7113\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.6713 - accuracy: 0.8104\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.5178 - accuracy: 0.8443\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.4255 - accuracy: 0.8739\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.3628 - accuracy: 0.9009\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.3054 - accuracy: 0.9217\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.2731 - accuracy: 0.9304\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.2491 - accuracy: 0.9365\n","287/287 [==============================] - 0s 98us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 92us/step - loss: 57.4556 - accuracy: 0.2089\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 35.0724 - accuracy: 0.6031\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 21.6616 - accuracy: 0.7572\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 13.2261 - accuracy: 0.8338\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 8.0012 - accuracy: 0.8825\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 4.8551 - accuracy: 0.9112\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 2.9948 - accuracy: 0.9330\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.9351 - accuracy: 0.9373\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 1.3197 - accuracy: 0.9469\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.9815 - accuracy: 0.9547\n","288/288 [==============================] - 0s 93us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 86us/step - loss: 57.7955 - accuracy: 0.3055\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 36.1952 - accuracy: 0.6379\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 22.5854 - accuracy: 0.7668\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 32us/step - loss: 13.9054 - accuracy: 0.8242\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 8.4845 - accuracy: 0.8773\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 5.1714 - accuracy: 0.9130\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 3.1879 - accuracy: 0.9347\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 2.0489 - accuracy: 0.9356\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.3833 - accuracy: 0.9487\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.0048 - accuracy: 0.9487\n","288/288 [==============================] - 0s 92us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 93us/step - loss: 58.4422 - accuracy: 0.2070\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 35.7139 - accuracy: 0.5591\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 22.0985 - accuracy: 0.7617\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 13.5467 - accuracy: 0.8626\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 8.2525 - accuracy: 0.8861\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 5.0445 - accuracy: 0.9217\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 3.1412 - accuracy: 0.9339\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 2.0552 - accuracy: 0.9339\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.4164 - accuracy: 0.9478\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.0406 - accuracy: 0.9513\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 89us/step - loss: 57.9259 - accuracy: 0.2009\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 35.9919 - accuracy: 0.5957\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 22.3603 - accuracy: 0.7870\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 13.6843 - accuracy: 0.8817\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 8.2840 - accuracy: 0.9157\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 5.0321 - accuracy: 0.9252\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.1060 - accuracy: 0.9400\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 1.9934 - accuracy: 0.9496\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 1.3576 - accuracy: 0.9478\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.9834 - accuracy: 0.9557\n","287/287 [==============================] - 0s 87us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 84us/step - loss: 57.1361 - accuracy: 0.1852\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 35.3007 - accuracy: 0.5643\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 22.0340 - accuracy: 0.7600\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 13.5763 - accuracy: 0.8600\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 8.3064 - accuracy: 0.8939\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 5.0842 - accuracy: 0.9209\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.1696 - accuracy: 0.9383\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 2.0414 - accuracy: 0.9487\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.4045 - accuracy: 0.9557\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 46us/step - loss: 1.0250 - accuracy: 0.9583\n","287/287 [==============================] - 0s 89us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 92us/step - loss: 10.0071 - accuracy: 0.2715\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 5.7158 - accuracy: 0.6928\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 4.4419 - accuracy: 0.8433\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 3.6834 - accuracy: 0.8956\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 3.1275 - accuracy: 0.9191\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 2.7067 - accuracy: 0.9426\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 2.3622 - accuracy: 0.9565\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.0834 - accuracy: 0.9574\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.8445 - accuracy: 0.9687\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 1.6315 - accuracy: 0.9774\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 85us/step - loss: 9.9008 - accuracy: 0.2811\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 5.7608 - accuracy: 0.6989\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 4.3706 - accuracy: 0.8564\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 3.5520 - accuracy: 0.9095\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 38us/step - loss: 2.9687 - accuracy: 0.9321\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.5213 - accuracy: 0.9443\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 2.1606 - accuracy: 0.9608\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.8749 - accuracy: 0.9678\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.6363 - accuracy: 0.9704\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 1.4315 - accuracy: 0.9756\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 97us/step - loss: 10.8880 - accuracy: 0.1330\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 6.1376 - accuracy: 0.5609\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 4.6353 - accuracy: 0.7852\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.7942 - accuracy: 0.8652\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.2063 - accuracy: 0.8991\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.7505 - accuracy: 0.9243\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 2.3923 - accuracy: 0.9435\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 2.0919 - accuracy: 0.9583\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 1.8506 - accuracy: 0.9635\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.6368 - accuracy: 0.9696\n","287/287 [==============================] - 0s 103us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 95us/step - loss: 8.9069 - accuracy: 0.3357\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 5.4894 - accuracy: 0.7043\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 4.1436 - accuracy: 0.8583\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 3.3289 - accuracy: 0.9009\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 2.7482 - accuracy: 0.9296\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 2.3052 - accuracy: 0.9513\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 1.9676 - accuracy: 0.9565\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 1.6924 - accuracy: 0.9609\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 1.4617 - accuracy: 0.9713\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.2806 - accuracy: 0.9765\n","287/287 [==============================] - 0s 101us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 96us/step - loss: 9.4398 - accuracy: 0.3096\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 5.6453 - accuracy: 0.7278\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 4.3821 - accuracy: 0.8557\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 3.5869 - accuracy: 0.8974\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 3.0060 - accuracy: 0.9278\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 2.5633 - accuracy: 0.9452\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 2.2040 - accuracy: 0.9565\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.9193 - accuracy: 0.9565\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.6734 - accuracy: 0.9661\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.4623 - accuracy: 0.9757\n","287/287 [==============================] - 0s 99us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 92us/step - loss: 4.3283 - accuracy: 0.2733\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 1.4997 - accuracy: 0.6919\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 1.0516 - accuracy: 0.8111\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 0.8251 - accuracy: 0.8877\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.7105 - accuracy: 0.9234\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.6274 - accuracy: 0.9469\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 0.5797 - accuracy: 0.9617\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.5353 - accuracy: 0.9730\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.5057 - accuracy: 0.9765\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.4799 - accuracy: 0.9817\n","288/288 [==============================] - 0s 96us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 95us/step - loss: 6.4137 - accuracy: 0.1941\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 2.1828 - accuracy: 0.5196\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.1502 - accuracy: 0.7955\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.8599 - accuracy: 0.8773\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.7218 - accuracy: 0.9225\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.6427 - accuracy: 0.9391\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.5913 - accuracy: 0.9513\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.5430 - accuracy: 0.9608\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 0.5098 - accuracy: 0.9721\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.4823 - accuracy: 0.9791\n","288/288 [==============================] - 0s 97us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 92us/step - loss: 4.1667 - accuracy: 0.3626\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.5260 - accuracy: 0.7061\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 1.0305 - accuracy: 0.8296\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.8311 - accuracy: 0.8896\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.7102 - accuracy: 0.9157\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.6348 - accuracy: 0.9348\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.5732 - accuracy: 0.9478\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.5347 - accuracy: 0.9557\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.4953 - accuracy: 0.9704\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.4647 - accuracy: 0.9757\n","287/287 [==============================] - 0s 96us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 91us/step - loss: 4.9352 - accuracy: 0.2304\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 1.8624 - accuracy: 0.6217\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.1984 - accuracy: 0.7748\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.9250 - accuracy: 0.8583\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.7718 - accuracy: 0.9000\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.6612 - accuracy: 0.9287\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.5802 - accuracy: 0.9530\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.5329 - accuracy: 0.9609\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.4897 - accuracy: 0.9730\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.4631 - accuracy: 0.9817\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 91us/step - loss: 6.0397 - accuracy: 0.1704\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 1.7870 - accuracy: 0.6322\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 1.1340 - accuracy: 0.7991\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.8971 - accuracy: 0.8826\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.7640 - accuracy: 0.9235\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.6711 - accuracy: 0.9365\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.6075 - accuracy: 0.9496\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.5581 - accuracy: 0.9583\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 0.5196 - accuracy: 0.9678\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.4864 - accuracy: 0.9774\n","287/287 [==============================] - 0s 102us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 90us/step - loss: 5.2931 - accuracy: 0.2663\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 1.4334 - accuracy: 0.6284\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.7100 - accuracy: 0.7885\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.4726 - accuracy: 0.8590\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.3470 - accuracy: 0.9095\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.2701 - accuracy: 0.9399\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 37us/step - loss: 0.2284 - accuracy: 0.9530\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.1943 - accuracy: 0.9643\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 0.1715 - accuracy: 0.9721\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.1504 - accuracy: 0.9748\n","288/288 [==============================] - 0s 98us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 92us/step - loss: 5.7668 - accuracy: 0.1793\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 1.4972 - accuracy: 0.5614\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.7332 - accuracy: 0.7903\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 35us/step - loss: 0.4953 - accuracy: 0.8738\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 33us/step - loss: 0.3897 - accuracy: 0.9069\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.3224 - accuracy: 0.9278\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 36us/step - loss: 0.2794 - accuracy: 0.9408\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.2389 - accuracy: 0.9426\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 34us/step - loss: 0.2145 - accuracy: 0.9574\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 38us/step - loss: 0.1923 - accuracy: 0.9626\n","288/288 [==============================] - 0s 94us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 94us/step - loss: 4.3526 - accuracy: 0.3000\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 1.1318 - accuracy: 0.6696\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.6374 - accuracy: 0.8183\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.4300 - accuracy: 0.8730\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.3276 - accuracy: 0.9026\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.2681 - accuracy: 0.9200\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.2204 - accuracy: 0.9487\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.1896 - accuracy: 0.9591\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.1636 - accuracy: 0.9661\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.1454 - accuracy: 0.9757\n","287/287 [==============================] - 0s 104us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 91us/step - loss: 4.4373 - accuracy: 0.3330\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.9978 - accuracy: 0.7261\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.5250 - accuracy: 0.8583\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 0.3844 - accuracy: 0.8948\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.3018 - accuracy: 0.9261\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 0.2471 - accuracy: 0.9409\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 0.2154 - accuracy: 0.9530\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.1861 - accuracy: 0.9617\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.1662 - accuracy: 0.9704\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 34us/step - loss: 0.1479 - accuracy: 0.9783\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 89us/step - loss: 5.6774 - accuracy: 0.1617\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 1.4328 - accuracy: 0.5609\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.6096 - accuracy: 0.8287\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 36us/step - loss: 0.3929 - accuracy: 0.8913\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 32us/step - loss: 0.2907 - accuracy: 0.9304\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.2397 - accuracy: 0.9461\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 37us/step - loss: 0.1982 - accuracy: 0.9591\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.1694 - accuracy: 0.9687\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 35us/step - loss: 0.1521 - accuracy: 0.9739\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 33us/step - loss: 0.1325 - accuracy: 0.9826\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 96us/step - loss: 76.2453 - accuracy: 0.5466\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 33.9109 - accuracy: 0.8842\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 13.9884 - accuracy: 0.9382\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 5.5574 - accuracy: 0.9312\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 2.2990 - accuracy: 0.9452\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 1.1800 - accuracy: 0.9182\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.7492 - accuracy: 0.9426\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.6077 - accuracy: 0.9399\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.5375 - accuracy: 0.9574\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 49us/step - loss: 0.5552 - accuracy: 0.9304\n","288/288 [==============================] - 0s 94us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 93us/step - loss: 75.3981 - accuracy: 0.5274\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 33.1751 - accuracy: 0.8773\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 13.6302 - accuracy: 0.9269\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 5.4090 - accuracy: 0.9391\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 2.2457 - accuracy: 0.9478\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 38us/step - loss: 1.1283 - accuracy: 0.9478\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.7394 - accuracy: 0.9478\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 38us/step - loss: 0.6385 - accuracy: 0.9321\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 54us/step - loss: 0.5897 - accuracy: 0.9295\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.5335 - accuracy: 0.9513\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 91us/step - loss: 76.5253 - accuracy: 0.5235\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 34.2578 - accuracy: 0.8791\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 14.3040 - accuracy: 0.9243\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 5.7779 - accuracy: 0.9365\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 2.4205 - accuracy: 0.9426\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 1.1931 - accuracy: 0.9530\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.7873 - accuracy: 0.9383\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.6264 - accuracy: 0.9426\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.5618 - accuracy: 0.9400\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5654 - accuracy: 0.9348\n","287/287 [==============================] - 0s 97us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 98us/step - loss: 76.2569 - accuracy: 0.5652\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 33.6685 - accuracy: 0.8609\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 13.8246 - accuracy: 0.9200\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 5.4894 - accuracy: 0.9322\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 2.2853 - accuracy: 0.9313\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.1354 - accuracy: 0.9374\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.7491 - accuracy: 0.9330\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.6071 - accuracy: 0.9426\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.5605 - accuracy: 0.9461\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.5429 - accuracy: 0.9435\n","287/287 [==============================] - 0s 93us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 93us/step - loss: 76.6654 - accuracy: 0.5278\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 33.7452 - accuracy: 0.9052\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 13.8737 - accuracy: 0.9452\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 5.5313 - accuracy: 0.9487\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 2.3031 - accuracy: 0.9513\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.1496 - accuracy: 0.9461\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.7481 - accuracy: 0.9426\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.6130 - accuracy: 0.9452\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.5366 - accuracy: 0.9496\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.5239 - accuracy: 0.9522\n","287/287 [==============================] - 0s 93us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 96us/step - loss: 10.0351 - accuracy: 0.6127\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 6.2046 - accuracy: 0.9356\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 38us/step - loss: 4.3772 - accuracy: 0.9600\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 3.2178 - accuracy: 0.9643\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 2.4296 - accuracy: 0.9756\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 1.8619 - accuracy: 0.9852\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 1.4591 - accuracy: 0.9843\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.1589 - accuracy: 0.9826\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.9272 - accuracy: 0.9852\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.7616 - accuracy: 0.9809\n","288/288 [==============================] - 0s 100us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 95us/step - loss: 10.5979 - accuracy: 0.5570\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 6.3179 - accuracy: 0.9347\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 4.5033 - accuracy: 0.9521\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 3.3376 - accuracy: 0.9800\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 2.5564 - accuracy: 0.9782\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 45us/step - loss: 1.9932 - accuracy: 0.9817\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 1.5794 - accuracy: 0.9791\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 1.2535 - accuracy: 0.9852\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 1.0122 - accuracy: 0.9843\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.8287 - accuracy: 0.9878\n","288/288 [==============================] - 0s 98us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 90us/step - loss: 10.6114 - accuracy: 0.5791\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 6.2967 - accuracy: 0.9000\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 4.4601 - accuracy: 0.9478\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 3.3238 - accuracy: 0.9757\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 2.5533 - accuracy: 0.9791\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 2.0229 - accuracy: 0.9783\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 1.6315 - accuracy: 0.9722\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 1.3075 - accuracy: 0.9843\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 1.0703 - accuracy: 0.9826\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.8773 - accuracy: 0.9878\n","287/287 [==============================] - 0s 91us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 92us/step - loss: 10.3074 - accuracy: 0.6087\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 6.2874 - accuracy: 0.9235\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 4.4349 - accuracy: 0.9635\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 3.2755 - accuracy: 0.9722\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 2.4925 - accuracy: 0.9791\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.9398 - accuracy: 0.9809\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.5240 - accuracy: 0.9835\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 1.2215 - accuracy: 0.9765\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.9783 - accuracy: 0.9835\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.7974 - accuracy: 0.9896\n","287/287 [==============================] - 0s 106us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 97us/step - loss: 10.4574 - accuracy: 0.5896\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 6.1342 - accuracy: 0.9252\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 4.2757 - accuracy: 0.9504\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 3.1183 - accuracy: 0.9678\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 2.3409 - accuracy: 0.9774\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.8063 - accuracy: 0.9861\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 1.4223 - accuracy: 0.9852\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 1.1292 - accuracy: 0.9852\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.9097 - accuracy: 0.9817\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.7647 - accuracy: 0.9748\n","287/287 [==============================] - 0s 94us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 105us/step - loss: 2.5541 - accuracy: 0.5875\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 1.0452 - accuracy: 0.9147\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.8571 - accuracy: 0.9626\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.7516 - accuracy: 0.9765\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.6896 - accuracy: 0.9835\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.6357 - accuracy: 0.9887\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.5869 - accuracy: 0.9904\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.5459 - accuracy: 0.9974\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 47us/step - loss: 0.5178 - accuracy: 0.9965\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.4886 - accuracy: 0.9974\n","288/288 [==============================] - 0s 114us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 105us/step - loss: 2.4243 - accuracy: 0.6075\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 1.0182 - accuracy: 0.9304\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.8295 - accuracy: 0.9704\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.7346 - accuracy: 0.9809\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.6711 - accuracy: 0.9922\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.6216 - accuracy: 0.9939\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.5854 - accuracy: 0.9922\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.5509 - accuracy: 0.9930\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.5089 - accuracy: 0.9974\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.4805 - accuracy: 0.9991\n","288/288 [==============================] - 0s 101us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 97us/step - loss: 3.6205 - accuracy: 0.4983\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 1.1209 - accuracy: 0.8965\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.8659 - accuracy: 0.9478\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 38us/step - loss: 0.7645 - accuracy: 0.9643\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.6874 - accuracy: 0.9809\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.6340 - accuracy: 0.9887\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.5956 - accuracy: 0.9887\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.5562 - accuracy: 0.9922\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5249 - accuracy: 0.9965\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.4961 - accuracy: 0.9965\n","287/287 [==============================] - 0s 102us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 94us/step - loss: 2.8742 - accuracy: 0.5548\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.0505 - accuracy: 0.9165\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.8587 - accuracy: 0.9557\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.7603 - accuracy: 0.9722\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.6854 - accuracy: 0.9817\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.6347 - accuracy: 0.9878\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.5903 - accuracy: 0.9904\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.5577 - accuracy: 0.9922\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.5188 - accuracy: 1.0000\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.4870 - accuracy: 0.9983\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 97us/step - loss: 3.3444 - accuracy: 0.4843\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 1.1058 - accuracy: 0.9113\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.8655 - accuracy: 0.9583\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.7610 - accuracy: 0.9783\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.6941 - accuracy: 0.9870\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.6483 - accuracy: 0.9896\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.6040 - accuracy: 0.9939\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.5671 - accuracy: 0.9965\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.5346 - accuracy: 0.9991\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.5105 - accuracy: 0.9965\n","287/287 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 96us/step - loss: 2.5590 - accuracy: 0.5135\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 45us/step - loss: 0.3665 - accuracy: 0.9060\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.2288 - accuracy: 0.9547\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 42us/step - loss: 0.1768 - accuracy: 0.9748\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 39us/step - loss: 0.1524 - accuracy: 0.9826\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.1296 - accuracy: 0.9913\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.1203 - accuracy: 0.9939\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.1066 - accuracy: 0.9983\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 44us/step - loss: 0.1002 - accuracy: 0.9983\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 43us/step - loss: 0.0946 - accuracy: 0.9991\n","288/288 [==============================] - 0s 95us/step\n","Epoch 1/10\n","1149/1149 [==============================] - 0s 108us/step - loss: 2.3690 - accuracy: 0.5431\n","Epoch 2/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.3952 - accuracy: 0.9051\n","Epoch 3/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.2488 - accuracy: 0.9495\n","Epoch 4/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.1958 - accuracy: 0.9669\n","Epoch 5/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.1558 - accuracy: 0.9826\n","Epoch 6/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.1355 - accuracy: 0.9896\n","Epoch 7/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.1254 - accuracy: 0.9904\n","Epoch 8/10\n","1149/1149 [==============================] - 0s 40us/step - loss: 0.1101 - accuracy: 0.9965\n","Epoch 9/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.0996 - accuracy: 0.9983\n","Epoch 10/10\n","1149/1149 [==============================] - 0s 41us/step - loss: 0.0928 - accuracy: 1.0000\n","288/288 [==============================] - 0s 98us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 100us/step - loss: 2.1197 - accuracy: 0.5504\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.3474 - accuracy: 0.9165\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.2317 - accuracy: 0.9574\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.1809 - accuracy: 0.9739\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 39us/step - loss: 0.1517 - accuracy: 0.9870\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.1311 - accuracy: 0.9870\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1161 - accuracy: 0.9922\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 46us/step - loss: 0.1033 - accuracy: 0.9939\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 43us/step - loss: 0.0957 - accuracy: 0.9965\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.0891 - accuracy: 0.9991\n","287/287 [==============================] - 0s 98us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 98us/step - loss: 2.1385 - accuracy: 0.5496\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.3135 - accuracy: 0.9296\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1995 - accuracy: 0.9661\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1597 - accuracy: 0.9817\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1359 - accuracy: 0.9887\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1206 - accuracy: 0.9930\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1075 - accuracy: 0.9983\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.0979 - accuracy: 1.0000\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.0913 - accuracy: 1.0000\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.0881 - accuracy: 1.0000\n","287/287 [==============================] - 0s 104us/step\n","Epoch 1/10\n","1150/1150 [==============================] - 0s 100us/step - loss: 1.7765 - accuracy: 0.5896\n","Epoch 2/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.3291 - accuracy: 0.9287\n","Epoch 3/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.2230 - accuracy: 0.9652\n","Epoch 4/10\n","1150/1150 [==============================] - 0s 41us/step - loss: 0.1716 - accuracy: 0.9817\n","Epoch 5/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1448 - accuracy: 0.9887\n","Epoch 6/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1242 - accuracy: 0.9904\n","Epoch 7/10\n","1150/1150 [==============================] - 0s 44us/step - loss: 0.1140 - accuracy: 0.9948\n","Epoch 8/10\n","1150/1150 [==============================] - 0s 45us/step - loss: 0.1095 - accuracy: 0.9939\n","Epoch 9/10\n","1150/1150 [==============================] - 0s 40us/step - loss: 0.1014 - accuracy: 0.9974\n","Epoch 10/10\n","1150/1150 [==============================] - 0s 42us/step - loss: 0.0916 - accuracy: 0.9991\n","287/287 [==============================] - 0s 112us/step\n","Epoch 1/10\n","1437/1437 [==============================] - 0s 88us/step - loss: 2.3042 - accuracy: 0.6646\n","Epoch 2/10\n","1437/1437 [==============================] - 0s 42us/step - loss: 0.9544 - accuracy: 0.9318\n","Epoch 3/10\n","1437/1437 [==============================] - 0s 43us/step - loss: 0.7911 - accuracy: 0.9687\n","Epoch 4/10\n","1437/1437 [==============================] - 0s 43us/step - loss: 0.6916 - accuracy: 0.9868\n","Epoch 5/10\n","1437/1437 [==============================] - 0s 41us/step - loss: 0.6283 - accuracy: 0.9930\n","Epoch 6/10\n","1437/1437 [==============================] - 0s 42us/step - loss: 0.5868 - accuracy: 0.9916\n","Epoch 7/10\n","1437/1437 [==============================] - 0s 43us/step - loss: 0.5376 - accuracy: 0.9944\n","Epoch 8/10\n","1437/1437 [==============================] - 0s 43us/step - loss: 0.5008 - accuracy: 0.9965\n","Epoch 9/10\n","1437/1437 [==============================] - 0s 40us/step - loss: 0.4650 - accuracy: 0.9986\n","Epoch 10/10\n","1437/1437 [==============================] - 0s 41us/step - loss: 0.4324 - accuracy: 0.9993\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=None, error_score=nan,\n","             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f601fb26550>,\n","             iid='deprecated', n_jobs=None,\n","             param_grid={'epochs': [1, 5, 10], 'hidden_size': [32, 64, 256],\n","                         'reg': [1, 0.1, 0.01, 0.001]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=0)"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"id":"2IPx7tydtKH6","colab_type":"code","outputId":"8afda2b8-a99c-464e-cc02-ef083a33c74e","executionInfo":{"status":"ok","timestamp":1587741504076,"user_tz":240,"elapsed":629,"user":{"displayName":"Hyuk Joon Kwon","photoUrl":"","userId":"09699940390854570602"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pandas as pd\n","res = pd.DataFrame(grid.cv_results_)\n","res.pivot_table(index=['param_epochs','param_hidden_size','param_reg'],values=['mean_test_score','rank_test_score'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>mean_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","    <tr>\n","      <th>param_epochs</th>\n","      <th>param_hidden_size</th>\n","      <th>param_reg</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"12\" valign=\"top\">1</th>\n","      <th rowspan=\"4\" valign=\"top\">32</th>\n","      <th>0.001</th>\n","      <td>0.317393</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.270666</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.212217</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.181657</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">64</th>\n","      <th>0.001</th>\n","      <td>0.452265</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.558779</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.560813</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.402192</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">256</th>\n","      <th>0.001</th>\n","      <td>0.873313</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.874018</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.869856</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.832953</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"12\" valign=\"top\">5</th>\n","      <th rowspan=\"4\" valign=\"top\">32</th>\n","      <th>0.001</th>\n","      <td>0.800213</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.793252</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.823241</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.826694</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">64</th>\n","      <th>0.001</th>\n","      <td>0.907416</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.895601</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.906047</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.903242</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">256</th>\n","      <th>0.001</th>\n","      <td>0.961029</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.951999</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.959633</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.940142</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"12\" valign=\"top\">10</th>\n","      <th rowspan=\"4\" valign=\"top\">32</th>\n","      <th>0.001</th>\n","      <td>0.904663</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.906052</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.913703</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.938071</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">64</th>\n","      <th>0.001</th>\n","      <td>0.935959</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.946416</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.936672</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.944316</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">256</th>\n","      <th>0.001</th>\n","      <td>0.967289</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>0.010</th>\n","      <td>0.971467</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0.100</th>\n","      <td>0.963799</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1.000</th>\n","      <td>0.934587</td>\n","      <td>13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          mean_test_score  rank_test_score\n","param_epochs param_hidden_size param_reg                                  \n","1            32                0.001             0.317393               33\n","                               0.010             0.270666               34\n","                               0.100             0.212217               35\n","                               1.000             0.181657               36\n","             64                0.001             0.452265               31\n","                               0.010             0.558779               30\n","                               0.100             0.560813               29\n","                               1.000             0.402192               32\n","             256               0.001             0.873313               22\n","                               0.010             0.874018               21\n","                               0.100             0.869856               23\n","                               1.000             0.832953               24\n","5            32                0.001             0.800213               27\n","                               0.010             0.793252               28\n","                               0.100             0.823241               26\n","                               1.000             0.826694               25\n","             64                0.001             0.907416               15\n","                               0.010             0.895601               20\n","                               0.100             0.906047               17\n","                               1.000             0.903242               19\n","             256               0.001             0.961029                4\n","                               0.010             0.951999                6\n","                               0.100             0.959633                5\n","                               1.000             0.940142                9\n","10           32                0.001             0.904663               18\n","                               0.010             0.906052               16\n","                               0.100             0.913703               14\n","                               1.000             0.938071               10\n","             64                0.001             0.935959               12\n","                               0.010             0.946416                7\n","                               0.100             0.936672               11\n","                               1.000             0.944316                8\n","             256               0.001             0.967289                2\n","                               0.010             0.971467                1\n","                               0.100             0.963799                3\n","                               1.000             0.934587               13"]},"metadata":{"tags":[]},"execution_count":99}]}]}